# LLM-Async

## 项目介绍

一个演示**异步函数调用**与**流式输出**的 Node.js 项目，解决 LLM 函数调用中的阻塞问题。本项目提供了两种模式：

- **非抢占式模式**（main 分支）：函数调用与内容生成并行进行，两者互不干扰
- **抢占式模式**（feat-abort-stream 分支）：当函数调用结果返回时，立即中断内容生成，优先处理函数结果

## 核心痛点解决

### 1. LLM 函数调用阻塞问题

传统 LLM 函数调用流程：
1. LLM 生成函数调用请求
2. 暂停生成，等待函数执行完成
3. 函数结果返回后，继续生成

**问题**：当函数执行耗时较长时（如 API 调用延迟），整个对话被阻塞，用户体验差。

### 2. 我们的解决方案

#### 非抢占式模式（main 分支）

```
LLM: 北京的天气是[函数调用]，让我介绍一下北京的景点...
                  ↓
                 (异步执行函数)
                  ↓
                 (继续生成内容)
                  ↓
                 (函数返回结果)
                  ↓
                 (整合所有信息)
```

- **特点**：函数调用与内容生成并行进行，用户可以在等待函数结果的同时获取其他信息
- **适用场景**：函数调用结果不影响后续内容生成，或希望最大化利用等待时间

#### 抢占式模式（feat-abort-stream 分支）

```
LLM: 北京的天气是[函数调用]，让我介绍一下北京的景点...
                  ↓
                 (异步执行函数)
                  ↓
                 (继续生成内容)
                  ↓
                 (函数返回结果)
                  ↓
                 (立即中断内容生成)
                  ↓
                 (优先处理函数结果)
```

- **特点**：当函数调用结果返回时，立即中断内容生成，优先处理函数结果
- **适用场景**：函数调用结果对后续内容至关重要，需要立即响应

## 项目结构

```
src/
├── config.js         # 配置文件，包含 API 客户端、函数映射和工具定义
├── functionHandler.js # 处理函数调用的模块，支持异步 Promise
├── enhancedChat.js    # 核心聊天逻辑，实现三轮对话流程
└── index.js          # 主入口文件
```

## 快速开始

### 环境准备

1. 安装 Node.js（建议 16+）
2. 克隆仓库并进入目录：
   ```bash
   git clone <repo_url>
   cd llm-async
   ```
3. 安装依赖：
   ```bash
   npm install
   ```
4. 复制并配置环境变量：
   ```bash
   cp .env.example .env
   # 在 .env 中填写你的 API Key
   ```

### 运行示例

```bash
node src/index.js
```

### 切换模式

```bash
# 非抢占式模式（默认）
git checkout main

# 抢占式模式
git checkout feat-abort-stream
```

## 技术实现

### 非抢占式模式（main 分支）

1. 第一轮对话：获取函数调用请求
2. 异步处理：创建 Promise 处理函数调用，但不等待结果
3. 第二轮对话：同时让 LLM 生成其他内容（如景点介绍）
4. 等待函数调用完成
5. 第三轮对话：整合函数结果与生成内容

### 抢占式模式（feat-abort-stream 分支）

1. 第一轮对话：获取函数调用请求
2. 异步处理：创建 Promise 处理函数调用
3. 第二轮对话：同时让 LLM 生成其他内容
4. 使用 AbortController 监听函数调用完成
5. 函数调用完成时，立即中断第二轮对话
6. 第三轮对话：整合函数结果与已生成内容

## 贡献指南

欢迎提交 Pull Request 或 Issue！

## 许可证

MIT

---

© 2025 llm-async 项目组